{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap2: An Asset Selling Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chapter to answer basic question: **When to sell an asset** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we use a simple class of policies known as:  *policy function approximations*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mathematical Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T12:33:31.902426Z",
     "start_time": "2020-12-21T12:33:31.899054Z"
    }
   },
   "source": [
    "* **State Variable**: $S_t$ that captures all the information we need ...($R_t$, $I_t$, $B_t$)\n",
    "* **Decsion Variable** : $x_t$ where $x_0$ is the design decision, while $x_t$ for t>0 represents control varilables.\n",
    "* **Exogenous Information**: The variable $W_t$ captures information that first becomes available between $t-1$ and $t$ from outside of our system.\n",
    "* **Transition Fucntion**:\n",
    "$$\n",
    "S_{t+1} = S^M(S_t, x_t,W_{t+1})\n",
    "$$\n",
    "* **Objective Function**: When there are elements of the *problem* that depend on the state variables, we represent costs/contribution as:\n",
    "\n",
    "$$\n",
    "C(S_{t},x_{t}) \\ or \\ C(S_t,x_t, W_{t+1})\n",
    "$$\n",
    "\n",
    "**Set of learning problems** : where we are trying to learn about a function which is not itself a function of state variable, it means:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means the state variable consists purely of belief state $B_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Narrative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are holding a block of shares of stock, looking for oppurtunity to sell.If we sell at time t, we receive a price that varies according to some random process over time. Once we sell the stock, the process stops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Variable:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two state variables:\n",
    "* The **Physical State** which says whether or not we are still holding the assest\n",
    "* The **Information State** the price of stock "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The physical State:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "  R_t=\\left\\{\n",
    "  \\begin{array}{@{}ll@{}}\n",
    "    1, & \\text{if we are holding the stock at time t}\\  \\\\\n",
    "    0, & \\text{if we are not longer holding the stock at time t}\n",
    "  \\end{array}\\right. \n",
    "$$\n",
    "\n",
    "If we sell the stock, we receive the price per share $p_t$. This means our state variable is:\n",
    "$$\n",
    "S_t=(R_t, p_t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Variable:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T13:41:09.474173Z",
     "start_time": "2020-12-21T13:41:09.467788Z"
    }
   },
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "  x_t=\\left\\{\n",
    "  \\begin{array}{@{}ll@{}}\n",
    "    1, & \\text{if we sell the stock at time t}\\  \\\\\n",
    "    0, & \\text{if we do not sell the stock at time t}\n",
    "  \\end{array}\\right.\n",
    "\\end{equation} \n",
    "$$\n",
    "we only can sell stock if we hold it,\n",
    "$$\n",
    "x_t < R_t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Policy:\n",
    "\n",
    "What is the policy: <br> **which is going to define how we make decision**\n",
    "\n",
    "$$\n",
    "X^{\\pi}(S_t)\n",
    "$$\n",
    "\n",
    "Example policy is we might be to sell if the price drops the below some limit point, thus we could write:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "  X^{sell-low}(S_t|\\theta^{low})=\\left\\{\n",
    "  \\begin{array}{@{}ll@{}}\n",
    "    1, & \\text{if}\\ p_t<\\theta^{low}  \\ \\text{and}\\ R_t=1  \\\\\n",
    "    1, & \\text{if}\\ t= T\\ \\text{and} \\ R_t = 1 \\\\\n",
    "    0, & \\text{otherwise}\n",
    "  \\end{array}\\right.\n",
    "\\end{equation} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exogenous Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only random process in our basic model is the change in price. Alternatively, naturally we simply write $W_t$ be the new price, in which we would write:\n",
    "\n",
    "$$\n",
    "W_{t+1} = (p_{t+1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the equation that describe how the states evolves. The transition equation is:\n",
    "\n",
    "$$\n",
    "R_{t+1} = R_{t} - x_{t}\n",
    "$$\n",
    "\n",
    "How the price evolves over time. \n",
    "\n",
    "$$p_{t+1} = p_t  + \\hat{p}_{t+1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transition Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "S_{t+1} = S^M(S_t, X^{\\pi}(S_t), W_{t+1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use our policy $X^{\\pi}(S_t)$, and if we choose sample path $\\omega$, that determine the sequence $W_1,W_2,W_3,...,W_T$...than the simulation of process can be written as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "(S_0,x_0 = X^{\\pi}(S_0)), W_1(\\omega), S_1, x_1 = X^{\\pi}(S_1), W_(\\omega),..., x_{T-1}, W_T(\\omega),S_T)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective Function\n",
    "The performance metric is how much we earn from selling our stock."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T14:16:26.040468Z",
     "start_time": "2020-12-21T14:16:26.037354Z"
    }
   },
   "source": [
    "$$\n",
    "C(S_t,x_t) = p_tx_t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can formulate the optimizatio problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T14:19:50.538018Z",
     "start_time": "2020-12-21T14:19:50.528895Z"
    }
   },
   "source": [
    "$$\n",
    "max \\ \\sum_{t=0}^{T-1} p_tx_t \\\\\n",
    "x_0,x_1,...,x_{T-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constraints of the Optimization:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sum_{t=0}^{T-1} x_t = 1, \\\\\n",
    "x_t \\leq 1, \\\\\n",
    "x_t \\geq 0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Including Uncertainty**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are simulating a policy following a sample path $\\omega$ of price $p_1(\\omega), p_2(\\omega),...$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "S_{t+1}(\\omega) = S^{M}(S_t(\\omega), X^{\\pi}(S_t(\\omega)), W_{t+1}(\\omega))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we follow policy $\\pi$ along this sample path, we can compute the performance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{F}^{\\pi}(\\omega) = \\sum_{t=0}^{T-1} p_t(\\omega)X^{\\pi}(S_t(\\omega))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for one sample path . We can simulate over sample of $N$ sampels ($\\omega^{1},...,\\omega^n,...\\omega^N$), and take average:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\overline{F}^{\\pi} = \\frac{1}{N} \\sum_{n=1}^{N}\\hat{F}^{\\pi}(\\omega^n)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we write out optimization problem in terms of finding the best policy, which we can write:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "max \\ \\ \\overline{F}^{\\pi} \\\\\n",
    "x \\in \\Pi\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sell_low Policy:\n",
    "In this policy we *sell* at that the price lower than, $\\theta^{sell-low}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "  X^{sell-low}(S_t|\\theta^{low}) =\\left\\{\n",
    "  \\begin{array}{@{}ll@{}}\n",
    "    1  & if \\ p_t < \\theta^{low} \\ and \\ R_t=1  \\\\\n",
    "    1, & t=T \\ R_t=1 \\\\\n",
    "    0, & otherwise\n",
    "  \\end{array}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High_Low policy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this policy , we will sell the asset if the price jumps *too high** or ** too low**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "  X^{high-low}(S_t|\\theta^{high-low}) =\\left\\{\n",
    "  \\begin{array}{@{}ll@{}}\n",
    "    1  & if \\ p_t < \\theta^{low} \\ or \\ p_t > \\theta^{high}   \\\\\n",
    "    1, & t=T \\ and \\ R_t=1 \\\\\n",
    "    0, & otherwise\n",
    "  \\end{array}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track Policy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps we just want to sell when the stock rises above a tracking signal. Tod this, first create a smoothed estimate of price:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\overline{p}_t = (1- \\alpha)\\overline{p}_{t-1} + \\alpha \\hat{p}_t$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consider a tracking policy that we might write:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "  X^{track}(S_t | \\theta^{track}) =\\left\\{\n",
    "  \\begin{array}{@{}ll@{}}\n",
    "    1  & if \\ p_t > \\overline{p}_t + \\theta^{track} \\    \\\\\n",
    "    1, & t=T \\ and \\ R_t=1 \\\\\n",
    "    0, & otherwise\n",
    "  \\end{array}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this policy, we are going to need to tweak our model, because we now $\\overline{p}_{t}$ in order to make decision. This means we would now write our state as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "S_t = (R_t, p_t, \\overline{p}_t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classes of Policies**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$F = \\{\"sell-low\",\"high-low\",\"track\"\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameter for each policy**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\theta^f \\in F$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Search over policies**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\pi \\in \\Pi$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Part:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the directory to to get module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/peyman/Documents/PhD_UiS/seqdec_powell_repo/Chap2_Assett_Selling/function'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/home/peyman/Documents/PhD_UiS/seqdec_powell_repo/Chap2_Assett_Selling/function\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules from function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AssetSellingModel import AssetSellingModel\n",
    "from AssetSellingPolicy import AssetSellingPolicy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the directory to to get parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/peyman/Documents/PhD_UiS/seqdec_powell_repo/Chap2_Assett_Selling/data'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/home/peyman/Documents/PhD_UiS/seqdec_powell_repo/Chap2_Assett_Selling/data\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet1= pd.read_excel(\"asset_selling_policy_parameters_edit.xlsx\", sheet_name=\"Sheet1\", usecols=[\"policy\", \"param1\",\"param2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy</th>\n",
       "      <th>param1</th>\n",
       "      <th>param2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sell_low</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high_low</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>track</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     policy  param1  param2\n",
       "0  sell_low       2     NaN\n",
       "1  high_low       4    10.0\n",
       "2     track       0     4.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, nan), (4, 10.0), (0, 4.0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = zip(sheet1[\"param1\"], sheet1[\"param2\"])\n",
    "param_list = list(params)\n",
    "param_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full grid Policy Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet2 = pd.read_excel(\"asset_selling_policy_parameters_edit.xlsx\", sheet_name=\"Sheet2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>low_min</th>\n",
       "      <th>low_max</th>\n",
       "      <th>high_min</th>\n",
       "      <th>high_max</th>\n",
       "      <th>increment_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   low_min  low_max  high_min  high_max  increment_size\n",
       "0        0        0      0.01         5           0.005"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters of the Dynamic Model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Policy</th>\n",
       "      <th>TimeHorizon</th>\n",
       "      <th>DiscountFactor</th>\n",
       "      <th>InitialPrice</th>\n",
       "      <th>InitialBias</th>\n",
       "      <th>UpStep</th>\n",
       "      <th>DownStep</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Iterations</th>\n",
       "      <th>PrintStep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>track</td>\n",
       "      <td>40</td>\n",
       "      <td>0.99</td>\n",
       "      <td>16</td>\n",
       "      <td>Up</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Policy  TimeHorizon  DiscountFactor  InitialPrice InitialBias  UpStep  \\\n",
       "0  track           40            0.99            16          Up       1   \n",
       "\n",
       "   DownStep  Variance  Iterations  PrintStep  \n",
       "0        -1         2          10         40  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet3 = pd.read_excel(\"asset_selling_policy_parameters_edit.xlsx\", sheet_name=\"Sheet3\")\n",
    "sheet3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias Term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Up</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Down</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>additional</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Up</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Down</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Up  Neutral  Down\n",
       "additional                    \n",
       "Up          0.9      0.1   0.0\n",
       "Neutral     0.2      0.6   0.2\n",
       "Down        0.0      0.1   0.9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biasdf = pd.read_excel(\"asset_selling_policy_parameters_edit.xlsx\", sheet_name=\"Sheet4\")\n",
    "biasdf_edit=biasdf.set_index('additional')\n",
    "biasdf_edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track Policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected policy is: track\n",
      "The T value is: 40\n",
      "The initial price is: 16\n",
      "The initial Bias is: Up\n",
      "The exog_params is: {'UpStep': 1, 'DownStep': -1, 'Variance': 2, 'biasdf':              Up  Neutral  Down\n",
      "additional                    \n",
      "Up          0.9      0.1   0.0\n",
      "Neutral     0.2      0.6   0.2\n",
      "Down        0.0      0.1   0.9}\n",
      "The nIteration is: 10\n",
      "The printStep is: 40\n",
      "The printIterations is: [0]\n"
     ]
    }
   ],
   "source": [
    "policy_selected = sheet3['Policy'][0]\n",
    "print(\"The selected policy is: {}\".format(policy_selected))\n",
    "\n",
    "T = sheet3['TimeHorizon'][0]\n",
    "print(\"The T value is: {}\".format(T))\n",
    "\n",
    "initPrice = sheet3['InitialPrice'][0]\n",
    "print(\"The initial price is: {}\".format(initPrice))\n",
    "\n",
    "initBias = sheet3['InitialBias'][0]\n",
    "print(\"The initial Bias is: {}\".format(initBias))    \n",
    "\n",
    "exog_params = {'UpStep':sheet3['UpStep'][0],'DownStep':sheet3['DownStep'][0],'Variance':sheet3['Variance'][0],'biasdf'\n",
    "               :biasdf_edit}\n",
    "print(\"The exog_params is: {}\".format(exog_params))    \n",
    "    \n",
    "nIterations = sheet3['Iterations'][0]\n",
    "print(\"The nIteration is: {}\".format(nIterations))    \n",
    "\n",
    "printStep = sheet3['PrintStep'][0]\n",
    "print(\"The printStep is: {}\".format(printStep))    \n",
    "\n",
    "printIterations = [0]\n",
    "print(\"The printIterations is: {}\".format(printIterations))    \n",
    "\n",
    "printIterations.extend(list(reversed(range(nIterations-1,0,-printStep))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy_names are: ['sell_low', 'high_low', 'track']\n",
      "state_names are: ['price', 'resource', 'bias']\n",
      "init_state are: {'price': 16, 'resource': 1, 'bias': 'Up'}\n",
      "decision_names are: ['sell', 'hold']\n"
     ]
    }
   ],
   "source": [
    "policy_names = ['sell_low', 'high_low', 'track']\n",
    "print(\"policy_names are: {}\".format(policy_names))    \n",
    "\n",
    "state_names = ['price', 'resource','bias']\n",
    "print(\"state_names are: {}\".format(state_names))    \n",
    "\n",
    "init_state = {'price': initPrice, 'resource': 1,'bias':initBias}\n",
    "print(\"init_state are: {}\".format(init_state))    \n",
    "\n",
    "decision_names = ['sell', 'hold']\n",
    "print(\"decision_names are: {}\".format(decision_names))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the biasdf_edit is \n",
      " .             Up  Neutral  Down\n",
      "additional                    \n",
      "Up          0.9      0.1   0.0\n",
      "Neutral     0.2      0.6   0.2\n",
      "Down        0.0      0.1   0.9\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "the biasdf_edit is \n",
      " .             Up  Neutral  Down\n",
      "additional                    \n",
      "Up          0.9      1.0   1.0\n",
      "Neutral     0.2      0.8   1.0\n",
      "Down        0.0      0.1   1.0\n"
     ]
    }
   ],
   "source": [
    "biasdf = exog_params[\"biasdf\"]\n",
    "print(\"the biasdf_edit is \\n .{}\".format(biasdf))\n",
    "print(type(biasdf))\n",
    "biasdf= biasdf.cumsum(axis =1)\n",
    "print(\"the biasdf_edit is \\n .{}\".format(biasdf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = AssetSellingModel(state_names, decision_names, init_state,exog_params,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = AssetSellingPolicy(M, policy_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "prev_price = init_state['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_info = {'sell_low': param_list[0],\n",
    "                   'high_low': param_list[1],\n",
    "                   'track': param_list[2] + (prev_price,)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sell_low': (2, nan), 'high_low': (4, 10.0), 'track': (0, 4.0, 16)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'track'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected policy track, time horizon 40, initial price 16 and number of iterations 10\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=0, hold=1)\n",
      "coin  0.4139840589481404  curr_bias  Up  new_bias  Up\n",
      "alpha = 4.0,prev_price = 16\n",
      "time=1, obj=0.0, s.resource=1, s.price=16.818962962840924, x=Decision(sell=0, hold=1)\n",
      "coin  0.8487800961190239  curr_bias  Up  new_bias  Up\n",
      "alpha = 4.0,prev_price = 16.818962962840924\n",
      "time=2, obj=0.0, s.resource=1, s.price=15.844213500127637, x=Decision(sell=1, hold=0)\n",
      "coin  0.45203620488154816  curr_bias  Up  new_bias  Up\n",
      "obj=15.844213500127637, state.resource=0\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=0, hold=1)\n",
      "coin  0.2720800519673423  curr_bias  Up  new_bias  Up\n",
      "alpha = 4.0,prev_price = 16\n",
      "time=1, obj=0.0, s.resource=1, s.price=19.325169358615813, x=Decision(sell=0, hold=1)\n",
      "coin  0.905534061916374  curr_bias  Up  new_bias  Neutral\n",
      "alpha = 4.0,prev_price = 19.325169358615813\n",
      "time=2, obj=0.0, s.resource=1, s.price=17.41361453720127, x=Decision(sell=1, hold=0)\n",
      "coin  0.3755268704762992  curr_bias  Neutral  new_bias  Neutral\n",
      "obj=17.41361453720127, state.resource=0\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=0, hold=1)\n",
      "coin  0.09168318648059992  curr_bias  Up  new_bias  Up\n",
      "alpha = 4.0,prev_price = 16\n",
      "time=1, obj=0.0, s.resource=1, s.price=19.54492051852451, x=Decision(sell=0, hold=1)\n",
      "coin  0.9746533545172668  curr_bias  Up  new_bias  Neutral\n",
      "alpha = 4.0,prev_price = 19.54492051852451\n",
      "time=2, obj=0.0, s.resource=1, s.price=16.93547988534935, x=Decision(sell=1, hold=0)\n",
      "coin  0.845463715621411  curr_bias  Neutral  new_bias  Down\n",
      "obj=16.93547988534935, state.resource=0\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=0, hold=1)\n",
      "coin  0.7718855570743978  curr_bias  Up  new_bias  Up\n",
      "alpha = 4.0,prev_price = 16\n",
      "time=1, obj=0.0, s.resource=1, s.price=15.397661463642024, x=Decision(sell=1, hold=0)\n",
      "coin  0.058599417274914245  curr_bias  Up  new_bias  Up\n",
      "obj=15.397661463642024, state.resource=0\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=0, hold=1)\n",
      "coin  0.5630457710972723  curr_bias  Up  new_bias  Up\n",
      "alpha = 4.0,prev_price = 16\n",
      "time=1, obj=0.0, s.resource=1, s.price=15.601160349553894, x=Decision(sell=1, hold=0)\n",
      "coin  0.6337684851009756  curr_bias  Up  new_bias  Up\n",
      "obj=15.601160349553894, state.resource=0\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=0, hold=1)\n",
      "coin  0.32637382885748367  curr_bias  Up  new_bias  Up\n",
      "alpha = 4.0,prev_price = 16\n",
      "time=1, obj=0.0, s.resource=1, s.price=19.30931856683528, x=Decision(sell=0, hold=1)\n",
      "coin  0.010789716774533442  curr_bias  Up  new_bias  Up\n",
      "alpha = 4.0,prev_price = 19.30931856683528\n",
      "time=2, obj=0.0, s.resource=1, s.price=20.57123121070621, x=Decision(sell=0, hold=1)\n",
      "coin  0.10655404328873319  curr_bias  Up  new_bias  Up\n",
      "alpha = 4.0,prev_price = 20.57123121070621\n",
      "time=3, obj=0.0, s.resource=1, s.price=23.65775469565424, x=Decision(sell=0, hold=1)\n",
      "coin  0.2744609047476718  curr_bias  Up  new_bias  Up\n",
      "alpha = 4.0,prev_price = 23.65775469565424\n",
      "time=4, obj=0.0, s.resource=1, s.price=22.795735744709045, x=Decision(sell=1, hold=0)\n",
      "coin  0.7876352836985036  curr_bias  Up  new_bias  Up\n",
      "obj=22.795735744709045, state.resource=0\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=0, hold=1)\n",
      "coin  0.5732916894272274  curr_bias  Up  new_bias  Up\n",
      "alpha = 4.0,prev_price = 16\n",
      "time=1, obj=0.0, s.resource=1, s.price=18.82950721784333, x=Decision(sell=0, hold=1)\n",
      "coin  0.25230738226248894  curr_bias  Up  new_bias  Up\n",
      "alpha = 4.0,prev_price = 18.82950721784333\n",
      "time=2, obj=0.0, s.resource=1, s.price=22.173455472137675, x=Decision(sell=0, hold=1)\n",
      "coin  0.34703831077049807  curr_bias  Up  new_bias  Up\n",
      "alpha = 4.0,prev_price = 22.173455472137675\n",
      "time=3, obj=0.0, s.resource=1, s.price=22.176324070451372, x=Decision(sell=0, hold=1)\n",
      "coin  0.020311694923608736  curr_bias  Up  new_bias  Up\n",
      "alpha = 4.0,prev_price = 22.176324070451372\n",
      "time=4, obj=0.0, s.resource=1, s.price=25.82098819098841, x=Decision(sell=0, hold=1)\n",
      "coin  0.5773741485181105  curr_bias  Up  new_bias  Up\n",
      "alpha = 4.0,prev_price = 25.82098819098841\n",
      "time=5, obj=0.0, s.resource=1, s.price=24.243902947987433, x=Decision(sell=1, hold=0)\n",
      "coin  0.9296106478220897  curr_bias  Up  new_bias  Neutral\n",
      "obj=24.243902947987433, state.resource=0\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=0, hold=1)\n",
      "coin  0.4326408307147147  curr_bias  Up  new_bias  Up\n",
      "alpha = 4.0,prev_price = 16\n",
      "time=1, obj=0.0, s.resource=1, s.price=19.44659502367821, x=Decision(sell=0, hold=1)\n",
      "coin  0.9844689697230611  curr_bias  Up  new_bias  Neutral\n",
      "alpha = 4.0,prev_price = 19.44659502367821\n",
      "time=2, obj=0.0, s.resource=1, s.price=16.84685532652269, x=Decision(sell=1, hold=0)\n",
      "coin  0.8262653217404742  curr_bias  Neutral  new_bias  Down\n",
      "obj=16.84685532652269, state.resource=0\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=0, hold=1)\n",
      "coin  0.4433318705856356  curr_bias  Up  new_bias  Up\n",
      "alpha = 4.0,prev_price = 16\n",
      "time=1, obj=0.0, s.resource=1, s.price=13.103911000739522, x=Decision(sell=1, hold=0)\n",
      "coin  0.6753561026946597  curr_bias  Up  new_bias  Up\n",
      "obj=13.103911000739522, state.resource=0\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=0, hold=1)\n",
      "coin  0.8662383958568906  curr_bias  Up  new_bias  Up\n",
      "alpha = 4.0,prev_price = 16\n",
      "time=1, obj=0.0, s.resource=1, s.price=22.33800862434439, x=Decision(sell=0, hold=1)\n",
      "coin  0.9282091767826981  curr_bias  Up  new_bias  Neutral\n",
      "alpha = 4.0,prev_price = 22.33800862434439\n",
      "time=2, obj=0.0, s.resource=1, s.price=22.959096047731283, x=Decision(sell=0, hold=1)\n",
      "coin  0.3886605993398763  curr_bias  Neutral  new_bias  Neutral\n",
      "alpha = 4.0,prev_price = 22.959096047731283\n",
      "time=3, obj=0.0, s.resource=1, s.price=24.3305666499575, x=Decision(sell=0, hold=1)\n",
      "coin  0.7922183625790814  curr_bias  Neutral  new_bias  Neutral\n",
      "alpha = 4.0,prev_price = 24.3305666499575\n",
      "time=4, obj=0.0, s.resource=1, s.price=20.26712226359752, x=Decision(sell=1, hold=0)\n",
      "coin  0.7101424377623707  curr_bias  Neutral  new_bias  Neutral\n",
      "obj=20.26712226359752, state.resource=0\n",
      "Contribution per iteration: \n",
      "0    15.844214\n",
      "1    17.413615\n",
      "2    16.935480\n",
      "3    15.397661\n",
      "4    15.601160\n",
      "5    22.795736\n",
      "6    24.243903\n",
      "7    16.846855\n",
      "8    13.103911\n",
      "9    20.267122\n",
      "dtype: float64\n",
      "Cumulative average contribution per iteration: \n",
      "0    15.844214\n",
      "1    16.628914\n",
      "2    16.731103\n",
      "3    16.397742\n",
      "4    16.238426\n",
      "5    17.331311\n",
      "6    18.318824\n",
      "7    18.134828\n",
      "8    17.575837\n",
      "9    17.844966\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh0AAAEpCAYAAAA3Y5DBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAABOC0lEQVR4nO3dd3hUVfrA8e+bQicBBKkZwIIKKuAioAF7V7Bgdy0/WV17w17Wuupad13dtSy2VcFe1gp2QQRRsGKXCb2n0Eny/v44d8JkmCQTMnNvZvJ+noeHzG3n3Du3vHPuKaKqGGOMMcakWlbQGTDGGGNM02BBhzHGGGN8YUGHMcYYY3xhQYcxxhhjfGFBhzHGGGN8YUGHMcYYY3zRZIIOEeklIioiOd7nD0XkT97fJ4nIhGBzWJ2IfCciewWdj2gicoOIPOX9HRKRlSKSHXS+EhWd/yRu8y0RObWW+Y+LyC3JTNM4IjJORI4IOh/G1EZEzheRv/mYXqO+5yQcdHgP6RUi0jyVGUrFg6Euqvq0qh7gZ5p1UdV+qvph0PmoiaoWqWobVa1I1jZFZC8RmZus7flBVQ9W1ScAROQ0EZkUdJ6C4Pe+i8jOQH/g1ahpJ4pIWERWicgrItJhM7b7F+/HyX61LNNLRD4QkdUi8kNty8as11xExnp5LBORmSJycMwy+3rbXO2l0bOGbW3pBV3zRaRERCaLyJCYZTqJyDPe/BUi8nTUvO+8Hw2Rf+Ui8r+o+Q+LyI8iUikip8Vs91QR+UJESkVkrojcEfVjrtZ9FJGhIjJRRJaLyBIReV5EusZsfxcR+djL1yIRuTBq3gfeeqUi8pWIHB41by8vv9H7dWrU/B1E5H3vePwiIkdGzTspZr3V3nnwB2/+DSKyIWaZrbx5fUTkVS9fy0XkHRHZLmqXHgFOEpEt432XfhGRq6PyvlZEKqI+f1fHuqd4x+NPUdNERP4mIsu8f38TEakrHwkFHSLSCxgOKDAykXWMSYXIzc3ULt2O02bk98/A0+r1bigi/YCHgJOBzsBq4F/1zMPWwDHAgjoWHQfMALYArgFeEJFOCSSRA8wB9gTygWuB57z7KyLSEXgJuA7oAEwHnq1hW22Az4E/eMs+AbwhIm2ilnkJWAiEgC2BuyIzvB81bVS1DdDWy9fzUet+BZwDfBkn7VbARUBHYAiwL3BpIvsItAceBnoBPYEy4LHIhr1j8Dbuu9wC2AaILoW+EOiqqnnAmcBTMUHL/Mh+ef8iPwhycAHq697xiqzbxzseT0ev5+37bzH7/2zMtn/zprcDXgO2w51704gKhlV1LfAWcEqcY+kbVb01av/OAqZE7Uu/mtYTkfbA1UBsYHImcAQu+N8ZGIG7LuvMSJ3/gL8Ak4F7gNdj5h0CfI87eeYBl3rTO+K+4GJgOfAJkOXN6wa8CCwBfgcu8KYfBKwHNgArga9qyM8VXlplwI/Avt70LOBK4FdgGfAc0MGb1wsXNOV4nz8E/uT9fRowKWr7ivtSfvby/wAg3rxs4G5gqZf386K3GyevCmwT9flx4JYEjtFsYD/v7xu8fXnS2+fvgEFR29wFdxMsw904no2kESc/p3nf5f1ACfBD5PhFfTevefn5BTgjat4NwFM1HM8OuJvHfGAF8Io3/VtgRNQ2cr1jNzAmX62BNUCl992v9PJyA/AC8BRQCvwJGAxM8Y7bAm9fmkVtqx8w0duHRcDVcfKfi3t4vBi9rjevt7ftyHfxCLA4av5/gYuizyNgB2AtUOHlvTjq+34AeMP7fqYCW9fw3USO6ZnecVyAdz158+vabwXOxZ23v3vT/oF7CJQCXwDDY77P571jWwZ8A/QBrgIWe+sdELV8PjDWS3secAvueqhp35vjHnRF3vfwINDSm7cXMBd3LS/0jmmN10OcY/UbMCzq863AM1Gft8bdS9omco/z1nkbdz+bjXftxVmmD7AuertePs9KNJ2Y7X0NjPL+PhP4NM41sX2C2yoF/uD9fYC3H9kJrLen9/23jjNvEnBaHetfAvwvkX2MM28XoCzme/xvgvs72DvvBkefUzUsu6N3bkrUtAnAzTUs/wFwfcy18lSC+eqAuxa3iJp2EvBBLevUdZ3Wdv8fiAuOynD3/vHUcP+PWuc0op55dSz7IC4I+xDvmelN/xQ4M+rzaOCzuraX6OuVU4CnvX8HikjnqHljgT+ralvvi33fmz4Gd1PphIv+rgZURLKA/+Ei6e64KPkiETlQVd/GnXSRiLJ/bEa8YqvzgF29NA/EXVwA5+Mirz1xD6wVuBv+5jgM2BUXwR3rpQNwBnAwMAB3wRyxmduHGo5RDcuOxJ1M7XBBwf0AItIMeBn3cOuAe5AeGXcLGw3BBWYdgeuBl2RjUfR4L0/dgKOBW0VknwT25b+4X0D9cL+q7vWmPwn8MWq5Q4AFqjojemVVXYU7rtG/VOZ7sw/HBR7tcOdgBXCxl//dcOfQOQAi0hZ4F/cA6Yb7pfRedFoi0hJ4BffwOFZV18fk5XfcxT/Qm7QHsFJEdvA+7wl8FLPOLKr/emgXNft44Ebcr7xfgL9Su72BbXEPjitkY/F9jfsd5Qjc99vX+/w57lztADwDPC8iLaKWH4H77trjAtd3cMF7d+Am3C/OiMeBctwxHejl70+17PvtuIf0AG+d7rgfMBFdvHz1xD1wE7oeRKQ1LjD8MWpyP9w9BQBV/RUXdPSJXT8eETkGWKeqb9axaD/gN1Uti5r2lTe9Xrz7aB82/oKM3YdVuOu0zm2LyACgGe78AhiKOz5PeEXfn4vInjWsfirwopfe5tiDTX8FR/IVu491rTsUWC4in4rIYhH5n4iEYrb5uoisxQXwH+JKhCK29F7J/C4i93rnSk0E98yKzXNPL19Pxswa4b0++U5Ezq5lu3sAC1V1WdS0WbgSgZrUdZ3Wdv9/BXcNd8D9iBhVSzr1IiKDgUG4wCNWtfOVRK+DBKKcYbiSh47e5x+Ai6PmF+GKVPJi1rsJV8S0Tcz0IUBRzLSrgMcSiShxN6/FwH5Absy8WVT/1d7Vy3sO9S/piP4V9Rxwpff3+7ggKzJvPza/pCPuMfLmzaZ6Sce7UfP6Amu8v/fA/eqMjuAnUXtJx/yY5afhiqULcA+26F9xtwGPx3430cfTO86VQPs46XXDReB53ucXgMtryNtexPxS8dL8uI5z9CLgZe/vE4AZNSx3A+6C/Qi4L/oYxFn2v7hfcF1wN+87cA/W2FKQGs+jqO/7P1GfDwF+qCHNyDHdPmraHcDYuvY76lzbp45jtQLoH3U8JkbNG4H7NZjtfW7rbbMdLghYh1dSEXWsP6jhGhJgFVGlOrhA6feo73o90CJqfo3XQ8w+dPfyFb3ue8SUNuCui71q21bUfv4M9Iq99uIsezIxv+ZwQeTjdaUTs04uLjh+KGraWOD2mOUmU3dJQx6ulOqqqGkPe8dotJfW8d552zFm3Va4ADvucaKOkg7gdFyg2DGRfYyZvzOuRCv6V/1PXj53BVrgrtPJNWz7YOCSqGldcPfGLNx1+nEkbW/534DLvb8P8M6/d+Js+zrgw5hpfXH3smxgd1xp3wlx1u3hnXcnxEzfFqiox/kRe53Wdv+PvZ9/ShJKOrx9nQ4M9T5/SPWSjgqq36u29c65Gu+rqomVdJwKTFDVpd7nZ7xpEaNwN9KwiHwkIrt50+/ERd0TROQ3EbnSm94T6CYixZF/uF800aUnNVLVX3A32xuAxSIyXkS6RW375ajtzvIOTELbjrEw6u/VuHeo4E68OVHzov+ur5qOUSL5aeG9p+wGzFPvW08wT7HLh73tdAOWa/VfcWHcTb42Bd56K2JnqCutmAyMEpF2uBvF07HL1aHa/ngVt14XkYUiUoorHesYlZdfa9nWUNzN7vaYYxDrI9yDcQ/czetDXAnHnsAnqlpZj/zXdC7VJHp/I99NXfsdb11E5FIRmeVVnivGvSKJXmdR1N9rgKW6sXLwGu//NrhrKxdYEHV9PYQr1YqnE+6B9kXU8m970yOWqHvfHZHo9VDs/d82atpK3MM3Wh4u4K3LDbgi/dkJLNuQdADwSnv/i3vondeQbXuldv/DBUK3Rc1aA8xW1bGqukFVx+POjcKYTRyFe/B/RD2Jazl0G3Bw1PMhMq+mfYzM3wZXz+FCVf0kJt8vq+rn3rlxI7C7iORHr+/t01vAASIy0pu2UFW/V9VKdaWVl+P96lfVDbhSwENx1+MY3I/JeBXXT8HVkYlO73tVna+qFar6Ke51yNEx+9QJ98rmX6o6LmabbXGvs+NK4Dqtz/0/XFM69XQO8LWqflbD/NjzNQ9YWcd9tfagwzuhjwX29G50C3HFu/1FpD+Ad3Icjrv5vIL7IlHVMlUdo6pb4YqGLhGRfXEn/u+q2i7qX1tVPcRLttYMe9t+RlWH4W6ECkSaI83BXQDR226hqvPq2mY9LMBFsxEFdSy/GnfzjegS+aOWY1Tf/HSPqTVcV55ilw/houX5QAfvFUX0vLqO3xxvvXY1zH8C94rlGFwRfE3bq+m7j53+b1yJ27bqKpRdjftlHcnLVrXkdQLuRvlezGvCWB/hKk/v5f09CXfD3pOab9B1nrsJiv7+It8N1L7fm+RBRIbjbrzH4kqh2uFufHXWMI9jDq6ko2PUtZWnGyugxe77UtwDpF/U8vnqKrFtkldI/HrQja8dol+dfEdU8bW4lgXNcb+c67IvcEHUPa4AV/nxijjLfgdsFXON9Kfm1wfVeNfdWNwPoVHew7CmfWiNq5tS06uL5rh77lw2rcD3NZt+J/HOz1OBJ+t6UMRJ+yBcXacRqvpNzLza9jHy+uJdXH2K/9aR77rylYM7RvEoUc84Vf1aVfdU1S1U9UDcfWJaTN4KcQ/yF+pIV4m6jrzKlhOA11Q13uvTHaj+KiI6zYZcp/Hu/6GaFq6nfYEjo66L3YG7ReR+b36185UEr4O6SjqOwJUU9MW9bxqAO3ifAKeISDNxTY3yvROrFFfMjogcJiLbeAejxNtOJe5LLhORK0SkpYhki8iOIrKrl+YioJcXKW9CRLYTkX28C24tGysfgnvv9FfvpI40GTu8roNQT88BF4pId+8hG+/GFG0mcKK3nwfhHlp4+avpGNXHFG+980Qkx9vfwXWssyXuJpsr7l32DsCbqjoHVzR3m4i0ENcscTSuomGNVHUB7lfLv0SkvbfdPaIWeQVX/+VCNn1PGm0RsEXsr5o42uLOtZUisj0Q/X71daCriFwkrvleW4lpSqiqd+BK7N4TV1s+3j79jDu3/gh8pKqlXv5GUXPQsQjoIe49a0NcJyKtxLXI+D82tmCobb/jaYurg7EEyBGRv7DpL+mEeN/xBNxNJ09EskRka9lYT6DavnslQY8A94rXVNC7Zg6Mt31vfn2uhzeJupZwpWcjRGS497C+CXgpUmonru+Cx2vY1r64d/sDvH/zcQ/xTeqDqepPuGv6eu8aORJXcvail85eIlLbg/LfuOtthKquiZn3MrCjiIwS9z7/L7hfmj/EbkREcnEPxjXAqXFK3l4G2otr3potIkfjfixNjtpGD1z9oSdi1sW7t7fAPfhyvX3N8ubtgzveo1R1Wuy6te2jiHTHvaK+X1Xj1RN4DPegG+Dt43W41wAlIrK9iBzsPTdyReSPuJLIj7xt7y0iPcUpwNUpim5SvbO3H61E5FLca+HHY9I/FVe/pVrpkogc7t3bRFw9hwsi2xaRPFxdqMmqWlPp3J64e2Q8DblOp3jrRu7nR1H3/T9Rp+G+xwHev+m4kqdrvPlP4n4YdBf3tmEMmx7PTdX27gVXHHp3nOnH4op7mnnLrMDdDD/HqwuBKxGZjXuvOxe4Lmr9brgKjwu9dT9jY/2FLXC/KlcAX8ZJe2e8wAVXLPg60M2bl4V7D/+jN/9X4FZvXi/qV6ejpnoYObhKkstwrVcuxtUbifseC1cJ5zsvP//19vuWBI7RbKrX6Xgqal7svgzC3QhX4ioSvRS9rZj8nEb11is/Ub2FQg/vmC73jt9ZUfOq8hEnD5Fme4u87+6lmHT/4+1nmzrOuUe9Y1vMxtYrT8UsswfuF/9KXAB8U8z3tyPuHf8K3Dl2ZQ3H8RbvuHWoIS/j8OogeJ/v8r7H7KhpH7LxPGqGa6WyHPeaotq5433ei5pr2EeOaaT1ykKi6r8ksN+x5222dzxLcb+ILqf282o/XJF85HOOt80e3ud83ANlrnfuzACOr2XfW+BeAf3m5WEWG1uqbXIcqOV6iHOsdsRdV9Hvsk/E1TFbhXsgdIia9x5RLbHqOAerjpH3+UHgwZjv6UPcA//HmGVPJk4dBG9epGR2LRtbaK0ETor5Dn7wtv0hXj2T2HzgHmKKK0mN3lZ0/YjhuLoeK3EPjOEx+bkK96owXl4/9LYf/W8vb94HuAdddLpvJbKPuIrrGjNvZUzaZ+NKV1fgXh0VeNN3wFUeLcPdHz4Hjoxa7xJvvdW4krn7qF4/7U5vmytxAUBsfcMW3nb3jXM8xuHuSyu97+eCqHmnevu0Kma/QlHbnQt0ruFY1/c67cWm9/8ZbGy9UmPrxahtnEaCrVfi3eu8z4Krc7bc+3cHddTnUNWqZqBmM4nr+OZBVe0ZdF4iRGQqLk+PxZl3Gu7EGeZznv4C9FHVP9a5cBMlri+D33EVpMsDzk6jJyLPAM+p6it1LNcMV7S9s8YU9acgT/8BnlfVd1KZjkkfInI+LnC6POi8NAZp1YFQYyCunsveuKLmzrjI/eWA87Qn7hfXUlx78J1xJVCNgrjmuKNxvwKNSQpVPTHB5dbjfiWnnKr+qe6lTFOiqv8MOg+NSZMZeyWJBPdeawWuSGsW1fseCMJ2uF9yxbj3akerewcfOBE5A1fU+Zaqfhx0fowxxgTHXq80ASJyA+795Wa92hDXL/+52ojHgjEgIg/ims/dLG6wwKdUtUftayW87eG4/ka2q3PhNBd9vjf02omz7auBrdKtRKQx5FtE3gLGq9e1uUlPVtKRQuIGoJoubkCdBeJGJPW1LkV9SZwRCrWRDz6X6STBwdRU9SxVvTlJaaq4vhQi2/7Er4AjVddNvHM7nmSd7xJnAEN141+kVcAB1fMtMSN2p4LEGfhTowZXNOnLgo4UEZFLgL/jau93xrWd/heuS2/jk1TeGBsTEckOOg/JEOR101TOlbqk+jjYcW7i6tNkxv4l3LQoH9dk6phalnmcWppS4ppMXYbrLGcVGzvbeQvXNOpdvG7HY9eNWr+mJlfP45pjluB62+znTT8T1/x3vZf//0VvC9eEdQ3VmyIOxFVgzfU+n46r57IC13a9Zy3HoKZ8DPGmRzdNPRLXZwEkNrDfaFzzyY9rS8ubtwWuaV6k2fctVG+Kuj0bB5D7ETdeS037FHfgO2/eGbgeN5fjumPvFjVPiTPIILUPJPdvXH8Vq7zv53E2NsfeC9dM72rv+5lN9aaZH1K9+dtpkX32jk90E8Dj2PT83MHbRjGu6erImHM7oUHuNuO6aY4LSiKd2f0daB6zz2NwQyUsAP4vgXP7Ctx1tg5XuX421a+dF3DNEMtwA2v1j/neNmleT+0DGEZfiyO941fsHc8dYq7hS728lXh5aFHDcTmN2gdyzCfOYH0x696Lu542aW5J9ebyRVRv9rpbXdc+9RiMkBoG/qR68/Qs3Ai2Ye+7fhLIj7kHnOrldSlwTTLu7fav4f+spCM1dsO1zW5oq5ZRwP64nhdH4AKOq3FdSWfhOqjZHG/h+snfEncTfRpAVR/2/r5D3cBdI6JXUtel+RSqDyh0IvCCqm4Q1zHZ1biulTvh+pKI7Q44kXxMxT3wogeaOxHXoRckNrDfnrgHY6QzqrhpeR7w0uuCu1GdGpnhdTQ10Ut7S9wYFv8Skb7EF3fgO69Dpdtwfdx0xd0sx8esu8kgg1r7QHIn4sb9aIvr2yZWF1xXyt29fXpY3ICJtVLVSMdu/b00qw2v7nXa9D9cC64tcd/H0zHbru8gd5DYdXMNriv7AbgeEAfjHj4RXXAP2O64wPMBEWlfx7l9Aq577HYav6ny4bigNTIY1yveMaiR1j6AIeC6tcddHxfhrpc3gf9J9c7ljsU9hHvjzovTakm2toEcHyfOYH0x6/6G+2FT13cVOT/aefs1JcFr/wgSGIxQExj4E3ccTsO1JNwK11X//THLDMNVst8X+ItsHLDRBMiCjtTYAtdBUkP7Wvinqi5S1234J8BUVZ2hbkyCl9k4Cmq9qOqj6rqcXof7BdNf6u4FNOIZ3E060t3x8WwMBs4CblPVWd6+3woMEK+H2HrmY1xUOm1x4/tEbmJn4X65zI1a9+iYYtsbVHWVej0i1pSW91piFG4Y69Wq+j3Ve2g8DNdh1mOqWq5udNwXcV26VyMiXXEPmrNUdYW68SEivZeeBDyqql96ebgK2M3rmyPidlUtVtUiXAdMA+IdtyivqupkdWNNrK1hmetUdZ2XjzdwD7GGGoq7yd+uqutV9X1ch3InRC3zsqpO886Dp6l7XyCx6+Yk4CZVXayqS3CBTXRT7A3e/A3qRoxdiXvw1OY+VZ2jm/YQGvGFqr6gro+Pe3CB0dAE9qcuxwFvqOpEb9t3AS1x3U1H522+qi7HBXoDatneYuDv3r4/iyuVO1Rcd/+HABd518RiXDB8fNS681X1n945XtNxqE0i1/5tqro86pp8SlWXeWnejSvFSrTe0EnAPar6m6quxF1Px8fcA25U1TWq+hWudV+84MX4zIKO1FgGdEzCu8vYwbhiP9c1cNgmxHWJfLuI/Cpu0LDZ3qy43YHH8SLuYdkV94unEhcQgeuN8B+ycYCv5bhXBJsMGJdAPp4BjhLX3f1RuN5pIwMZ9aTugf2qBj6rI61OuCL1mgbx6wkMkeoDFJ5E1Bg6UWoc+A5XIlM1EJN3o1xG9WPTkIHh4lmh1Ycrrxo8roG6AXO0etfbsQMD1ndfILHrptpxZNN9WhYTtCTjOFbN9/Z5Lsk7jtHnRKWX1uYex5oGcuxJ3YP1NWTgSkjs2q/vYIS1iXce5FD9HrA556BJMQs6UmMK7v3wEbUss4oaBoLbDNW25f1671TDsifiiov3w13kvSKref/X2obae6BOwP1KOxHXhC2yzhzgz1p9wL2W6kZlrFc+vBKHMK7kIPrVSiSdugb2i96P2tJagit2rmkQvzm4sVei02qjqvHGPalt4Lv5uBuzS9i9ttmCugfTi92XRKZHtPfSiYgePK4h5998oECqj4+UyMCAdUnkuql2HKm+T3XZ3ONYdT54+9wjKs0aB3RMYLux54R4aW3ucaxpIMe6ButLJK/R4i2byLVftZ7UPchZvY4dbl/Lqf7DzDRCFnSkgKqW4DoMe0BEjhA3wFCuuMGK7vAWmwkcIiIdRKQL7r3u5voJN9Txod675mtxRZXxtMXdgJbhbpa3xsxfRO2jtIILAE7BDe0cHQw8CFwlbqAyvNcXm7yGSDAfkXQuxJWoPB+TTn0G9qsxLXXDuL8E3OB9T9t7+xbxOtBHRE72vsNcEdk13vthrX3gu3HA/4kbyKq5l4epmthw6g0ZSO5GcYN3Dce9Koocx5m4kqRW4prGjo6TZk3nwVTcw/Zybx/3wtU5iq2jUi8JXjfjgGu977yjt3ytAxJGSeTcjucPInKUVwJzEe5cigz3PZMaBnSk7gEMn8O9/tjXu27HeNuOF6QnoqaBHOsarK++luBKOKOPZX2ufah7kLNaB/7EnQcXi0hvEWnDxjogNnxAI2dBR4p47ygvwQUAS3C/BM7DjbgKrsLhV7ii/glsHEl0c9IqAc7BDao2j40DZsXzJK4EYR7wPRtvnhFjgb5eMekrxPcarlLmQu99aSQfLwN/A8Z7rzG+xZVUbE4+wN1Y9gTeV9WlUdP/4eVhgoiUeesOibN+ommdhysBWcjGQfnWeftUhqt0dzwbB2H7GzUHdSfj6hX8gHvHfpG3nXdxI2a+iGtBsDXV36nX5n1cC4eFIrK0roWjRAZUnI+rV3GWbhyx9F5cC4FFuDosT8esewPwhHceVKsHoq5b8RG473YprknrKRpnNNT6SuC6uQU3eNnXuMHMvvSmJSKRczueV3Eleytw3+9RunEMlwtxx6IY99qtarve8RgH/OalWe2VjKr+iBvF+J+44zgCNzLr+nrkLdpU3HW5FFcZ9GhVXebNOwU3KN/33n68gKvQXG+qutrb/mRvv4bW89oH17rlbdwPpjCuhVb065dIcLxMRL6Ms/6juGv1Y9x4RWtxFZpNI2c9khoTQ0T+BnRR1VPrXNiYRkACGsjRmPqykg7T5InI9iKysziDca8aGtrc2RhjTAzrGc4Y9355HK5G/CLgblyRujHGmCSy1yvGGGOM8YW9XjHGGGOML+z1Shrq2LGj9urVK+hsmAz1xRdfLFXVmvp5SRk7r00qBXVem+os6EhDvXr1Yvr06UFnw2QoEQnXvVTy2XltUimo89pUZ69XjDHGGOMLCzqMMcYY4wsLOowxxhjjCws6jDHGGOMLCzqMMcYY4wsLOowxxhjjCws6jDHGGOMLCzqMMcZUWbJqCY/PfDzobJgMZUGHMcaYKmf87wz+79X/I1xsfWmZ5LOgwyciUiAiH4jI9yLynYhcGDN/jIioiHQMKo/GmKbtrZ/f4tUf3QDL4RILOkzyWdDhn3JgjKr2BYYC54pIX3ABCXAAUBRg/owxTdi68nVc8PYFdGzlfvcUldjtyCSfBR0+UdUFqvql93cZMAvo7s2+F7gc0ICyZ4xp4u769C5+Wf4LY0eOBSzoMKlhQUcARKQXMBCYKiKHA/NU9atgc2WMaarCxWH++slfGbXDKEZuN5JOrTpZ0GFSwkaZ9ZmItAFeBC7CvXK5Gvdqpa71zgTOBAiFQinMoTH+sfO6cbj4nYsREe458B4AQvkhCzpMSlhJh49EJBcXcDytqi8BWwO9ga9EZDbQA/hSRLrErquqD6vqIFUd1KlTJz+zbUzK2HkdvHd+eYeXf3iZa4dfSyjfBX4WdJhUsaDDJyIiwFhglqreA6Cq36jqlqraS1V7AXOBXVR1YYBZNcY0EevK13H+W+ezbYdtuWS3S6qmh/JDhEvCqFo1M5NcFnT4pxA4GdhHRGZ6/w4JOlPGmKbrnin38PPyn/nnwf+keU7zqumh/BAr16+kZF1JgLkzmcjqdPhEVScBUscyvfzJjTGmqSsqKeKWT27hyO2P5MBtDqw2L/KapaikiHYt2gWQO5OprKTDGGOaoDETxqCq3HvgvZvMiw46jEkmCzqMMaaJmfjrRF74/gWuGX4NPdv13GS+BR0mVSzoMMaYJmR9xXrOf+t8tumwDZfufmncZbZsvSXNsptZ0GGSzup0GGNME3LvlHv5cdmPvHnim9Uqj0bLkiwK8gos6DBJZyUdxhjTRMwtncvNH9/M4dsdzsHbHlzrstZXh0kFCzqMMaaJGDNhDBVawd8P+nudy1rQYVLBgg5jjGkC3vvtPZ777jmuGnYVvdr1qnP5UH6IeWXzKK8sT33mTJNhQYcxxmS4SOXRrdpvxeWFlye0Tig/RKVWsqBsQYpzZ5oSCzqMMSbD/eOzfzBr6SzuO+g+WuS0SGgdazZrUsGCDmOMyWDzSudx40c3MqLPCA7tc2jC61nQYVLBgg5jjMlgl068lPLK8oQqj0YryCsALOgwyWVBhzHGZKgPfv+A8d+O58phV7JV+63qtW7rZq3p0LKDBR0mqSzoMMaYDLShYgPnvXUevdv15orCKzZrG6H8EEWlFnSY5LEeSY0xJgP9c9o/+X7J97x6/Ku0zG25WdsI5YeYXTw7uRkzTZqVdBhjTIaZXzafGz68gUO3PZQRfUZs9nZCedZBmEkuCzqMMSbDXPf+dayvWM8/DvoHIrLZ2wnlhyheW0zputIk5s40ZRZ0GGNMhvm46GNGbDeCrTts3aDtRJrNzimZk4xsGWNBhzHGZJJKraSopIit2tWvtUo81leHSTYLOowxJoMsWrmI9RXrqwKGhrCgwySbBR3GGJNBIgFCz3Y9G7ytLm26kJOVY0GHSRoLOowxJoOES8IA9MxveNCRnZVNj7we1leHSRoLOowxJoOEi72gIwklHeB1EGYlHSZJLOgwxpgMEi4J065FO/Ka5yVlexZ0mGSyoMMYYzJIuCSclEqkEaG8EHNL51JRWZG0bZqmy4IOY4zJIEUlRUmpzxERyg9RXlnOwpULk7ZN03RZ0GGMMRkkXBxOetAB1mzWJIcFHcYYkyFK1pZQsq4kaZVIwYIOk1wWdPhERApE5AMR+V5EvhORC73pd4rIDyLytYi8LCLtAs6qMSZNJbO5bERBfgFgQYdJDgs6/FMOjFHVvsBQ4FwR6QtMBHZU1Z2Bn4CrAsyjMSaNJbu5LEBe8zzatWhnQYdJCgs6fKKqC1T1S+/vMmAW0F1VJ6hqubfYZ0CPoPJojElvkZKOZLZeiWzPOggzyWBBRwBEpBcwEJgaM+t04K0a1jlTRKaLyPQlS5akOIfG+MPO6+QqKimieXZztmy9ZVK3a311mGSxoMNnItIGeBG4SFVLo6Zfg3sF83S89VT1YVUdpKqDOnXq5E9mjUkxO6+TK9JHR5Yk99YeyrOgwySHBR0+EpFcXMDxtKq+FDX9NOAw4CRV1YCyZ4xJc+HicFLrc0SE8kMsX7OcletXJn3bpmmxoMMnIiLAWGCWqt4TNf0g4HJgpKquDip/xpj0Fy5Jbh8dEZE6InNK5iR926ZpsaDDP4XAycA+IjLT+3cIcD/QFpjoTXsw0FwaY9LS2vK1LFy5MKVBh71iMQ2VE3QGmgpVnQRInFlv+p0XY0zmiZRCJLvlSvQ2LegwDWUlHcYYkwEiAUEq6nR0bduVbMm2oMM0mAUdxhiTAVLRG2lETlYO3fO6W18dpsEs6DDGmAwQLg6TJVn0yEtN/4LWV4dJBgs6jDEmA4RLwnRr243c7NyUbN+CDpMMFnQYY0wGiHQMliqhvBBzSuZQqZUpS8NkPgs6jDEmA4SLU9NHR0QoP8SGyg0sWrkoZWmYzGdBhzHGpLmKygrmls5NedAB1mzWNIwFHcYYk+YWrlzIhsoNKWkuG2FBh0kGCzqMMSbNpbK5bIQFHSYZLOgwxpg0Fy72go4UlnTkt8gnr3meBR2mQSzoMMaYNBcp6Uhl65XI9q2DMNMQFnQYY0yaKyopokPLDrRp1ial6VhfHaahLOgwxpg0l6oh7WOF8izoMA1jQYcxxqS5cHE4pfU5IkL5IZauXsrqDatTnpbJTBZ0GGNMGlNV/0o6vDojc0rmpDwtk5ks6DDGmDS2Yu0KVq5fmfJKpGDNZk3DWdBhjDFprKq5rI8lHRZ0mM1lQYcxxqSxSADgR52Obm27IYgFHWazWdBhjDFpzI/eSCNys3Pp1rab9dVhNpsFHcYYk8bCxWFa5rSkY6uOvqRnfXWYhrCgwxhj0li4xDWXFRFf0rOgwzSEBR3GGJPGwiVhX1quRITyQ8wpmUOlVvqWpskcFnQYY0waCxf700dHRCg/xLqKdSxZtcS3NE3msKDDGGPS1JoNa1iyeonvQQc0vmazqhp0FkwCLOgwxpg05Wdz2YjGGnS8//v75N+ez7R504LOiqmFBR3GGJOm/GwuG1HVFXpp4+oKPVwSpnRdKZ1adQo6K6YWFnT4REQKROQDEfleRL4TkQu96R1EZKKI/Oz93z7ovBpj0kNVb6Q+lnS0b9Ge1rmtG11JR7g4TJZk0SOvR9BZMbWwoMM/5cAYVe0LDAXOFZG+wJXAe6q6LfCe99kYY+oULgmTLdl0a9vNtzRFpFE2mw2XhOnWthu52blBZ8XUwoIOn6jqAlX90vu7DJgFdAcOB57wFnsCOCKQDBpj0k5RSRHd87qTk5Xja7qNNejws+mw2TwWdARARHoBA4GpQGdVXeDNWgh0Dipfxpj04teQ9rEaZdDhc9Nhs3ks6PCZiLQBXgQuUtXS6Hnq2nzFbfclImeKyHQRmb5kibWPN5nBzuuGCReHfa3PERHKD7Fo1SLWlq/1Pe14KiormFM6x4KONGBBh49EJBcXcDytqi95kxeJSFdvfldgcbx1VfVhVR2kqoM6dbLa2SYz2Hm9+cory5lbOjewkg6AuaVzfU87ngUrF1BeWR5IAGbqx4IOn4gbGGEsMEtV74ma9Rpwqvf3qcCrfufNGJN+5pfNp0IrAqnH0Nj66qhqxWMlHY2ev7WPmrZC4GTgGxGZ6U27GrgdeE5ERgNh4NhgsmeMSSdBPmgbXdBR4n/TYbN5LOjwiapOAmoaBnJfP/NijEl/QfRGGtG9bXcEaTxBh5V0pA17vWKMMWko8us+iNcrzXOa06VNl8YTdJSE2aLlFrRu1jrorJg6WNBhjDFpKFwcplOrTrTKbRVI+o2p2Wy4JJhWPKb+LOgwxpg0FPSDtlEFHdZHR9qwoMMYY9JQ0D1wRoKOoIeUV9XAOkkz9WdBhzHGpBlVDfzXfSg/xJryNSxbsyywPAAsW7OM1RtW2+uVNGFBhzHGpJlla5axpnxN4EEHBN9s1lqupBcLOowxJs0EMaR9rEYTdFgfHWnFgg5jjEkzVQ9aK+nY2F+JlXSkBQs6jDEmzURKOoKsSLpFyy1omdMy8KAjXBymdW5rOrTsEGg+TGIs6DDGmDQTLgn+QSsijaLZbKTpsBveyjR21g36ZhCR7YAzge29SbOAR1T1x+ByZYxpKopKihrFg7bRBB32aiVtWElHPYnIbsCHQBnwMPAIsAr4QESGBpg1Y0wT0VgetI0i6LCOwdKKlXTU31+AE1T1w6hpr4jI+8D1wMGB5MoY02SEi8MM7jY46GwQyg+xYOUC1pWvo3lOc9/TX7V+FcvWLLOWK2nESjrqb+uYgAMAVf0I2Mr/7BhjmpLG9KCNVGSdVzYvkPQbQyseUz8WdNRfWS3zVvmWC2NMkxTk6LKxgm422xj6KzH1Y69X6q9ARO6LM12A7n5nxhjTtDSmHjgDDzqspCPtWNBRf5fVMm+6b7kwxjRJVZ1hNYJf9z3yegDBlnTkZuXStW3XQNI39WdBRz2p6hOx00SkPVCsQQ+3aIzJeOGSMDlZOXRtE/yDtkVOCzq37hxoSUePvB5kidUUSBf2TdWTiPxFRLb3/m7utVr5FVgkIvsFmztjTKYLl4QpyCsgOys76KwAwTabjXQMZtKHBR31dxwQ6QTsVFxdjk7AnsCtQWXKGNM0hIsb14M20KDD+uhIOxZ01N/6qNcoBwLjVbVCVWdhr6uMMSkWLgk3ipYrEZGgw++3y+sr1jO/bL4FHWnGgo76WyciO4pIJ2BvYELUvFYB5ckY0wRsqNjQ6B60ofwQqzasYsXaFb6mO7d0Loo2qlIfUzcLOurvQuAF4AfgHlX9HUBEDgFmBJkxY0xmm1c2j0qtbHRBB/jfgqUxNR02ibPXAfVXiBtvBUBF5GJgKTBJVU8ILlvGb1PnTqVSKxnQZQAtc1sGnR3TBDTGzrCig44BXQb4lm5VHx2N6FiYulnQUX9t40zrBVwjIjeo6nif82MCMPbLsfzpf38CICcrh/6d+zO4+2AGdx/MkO5D2K7jdtaMzyRdY+wMK+iSjoK8Al/TNQ1jQUc9qeqN8aaLSAfgXcCCjgz3zi/v8OfX/8wBWx/A2YPOZurcqUybP42nvn6Kf0//NwB5zfMY1G0QQ7oPqQpGurXtFnDOTbqretDmN54HbadWnWie3dz/oKMkTNc2XQMZaM5sPgs6kkRVl4uIBJ0Pk1ozFszg6OePZqfOO/HCMS/Qtnlbjtj+CAAqtZIflv7AtHnTmDZvGlPnTeXOT++kvLIccL03Du4+mMHdBjOkhwtGWuVa3WOTuHBJmM6tO9Mip0XQWakiIhTkFwQSdNirlfRjQUeSiMjeQI3Vt0XkUeAwYLGq7uhNGwA8CLQAyoFzVHVa6nNrNkdRSRGHPnMo7Vu0540T36Bt8+pv2rIki76d+tK3U19OG3AaAGs2rGHmwplMnTe1Khh5adZLgPuFeN/B93Fcv+OweNUkoqikqFE+aIPoqyNcHGZQt0G+pmkazoKOehKRb4DYBukdgPnAKbWs+jhwP/Bk1LQ7gBtV9S2v9csdwF5Jy6xJmuK1xRzy9CGs3rCayadPTvhVScvcluxWsBu7FexWNW3p6qV8NvczbvroJk548QSe/uZp/n3ov6vGsTCmJuGSMP079w86G5sI5YeY+OtE39Kr1ErmlM5h1A6jfEvTJIfVdKu/w4ARUf8OA7ZT1cGq+kNNK6nqx8Dy2MlAnvd3Pi5wMY3MuvJ1HPnskfy07CdePu5l+m3Zr0Hb69iqI4f1OYwpo6dw9wF3895v79H3gb48OP1BKrUySbk2mUZVXUlHI6pEGhHKCzG/bD4bKjb4kt7ClQtZX7G+UZb6mNpZ0FFPqhqO+Vekqqs2c3MXAXeKyBzgLuCqmhYUkTNFZLqITF+yZMlmJmfqS1UZ/dpoPpz9IY8d/hh79947advOzsrmkt0u4dtzvmXX7rty9htns/cTe/PTsp+SlkZjZ+d14havWsza8rWN8kEbyg+hKPPK5vmSnvXRkb4s6AjW2cDFqloAXAyMrWlBVX1YVQep6qBOnTr5lsGm7pr3r+Hpb57mr/v8lZN2PiklaWzVfivePfldxo4cy9eLvmbnf+/M7ZNuT9mvRlVl9YbVKdl2fdl5nbhIc9nG1AV6hN/NZq2PjvRlQUewTgVe8v5+HhgcYF5MjIemP8Rtk27jzF3O5KphNRZCJYWIcPrA0/n+nO85rM9hXPXeVQz+z2C+XPBlUra/vmI9E36dwLlvnEvBvQXc9NFNSdmu8U9j/nXvd9ARSacxHgtTOws6gjUfNzotwD7AzwHmxUR546c3OOfNczhk20N44NAHfGtd0rVtV1449gVeOvYlFq5cyOBHBnPFxCtYs2FNvbdVuq6UZ799lhNePIFOd3biwKcO5PGvHmdIjyEUFhSmIPcmlaoetI3w132k3xDfSjqKw7Rv0X6TFmSm8bPWKz4RkXG4likdRWQucD1wBvAPEckB1gJnBpdDEzF9/nSOfeFYBnYZyLNHP0tOlv+XyZE7HMnevffmsgmXccend/DyDy/zyIhH2LPXnrWuN79sPq/9+Bqv/PAK7//+PhsqN9CpVSeO6XsMR2x/BPv23te6bE9T4ZIwec3zaNeiXdBZ2USr3FZ0bNXR19crjTH4MnWzoMMntYzL8gdfM2Jq9fuK3znsmcPo1KoTr5/4Om2atQksL+1atOORkY9wwk4ncMb/zmCvJ/bizF3O5I797yC/RT7g6mfMWjqLV354hVd/fJVp81w3L9t02IYLh1zIEdsfwdAeQ8nOyg5sP0xyhEvCjfp1gp99dYRLwmzdfmtf0jLJZUGHMZ7la5ZzyDOHsL5iPR+c+gFd2nQJOksA7NN7H745+xuu/+B67vnsHl7/+XVu3OtGflz6I6/8+Aq/LP8FgMHdB3PrPrdy+PaHs0PHHazDsQwTLg43ykqkEaH8ED8vS/0bYlUlXBxmn177pDwtk3wWdBgDrC1fyxHjj+C3Fb8x8eSJ7NBph6CzVE2r3FbcecCdHLfjcYx+bTRn/O8McrNy2af3PozZbQwjtxtpY7tkuHBJuFHXxQnlhXj3t3dR1ZQGvMVriylbX2avV9KUBR2myavUSk595VQ+KfqEcaPGsUfPPYLOUo0GdRvE9DOmM3XeVHbuvDN5zfPqXsmkvdJ1pRSvLW7UD9pQfoiV61dSsq4kpfVOGuNIuyZx1nrFNHlXvnslz333HHfsdwfH73h80NmpU252LsNCwyzgSICqMnXu1KpB99JVOjQR9avZbFXT4UYcgJmaWdBhmrQHpj3AnZ/eyTmDzuHS3S8NOjsmyR764iGGjh3KTv/eidd+fA3V2GGT0kM6PGh9CzqspCOtWdBhmqw3fnqDC96+gJHbjeS+g++zipcZpnRdKdd/eD39O/dHVTl8/OHs/cTeTJ8/Peis1Vs6PGj9LOlomdOSjq06pjQdkxoWdJgm6edlP3PSSyfRv3N/njnqGWtSmoHumHwHi1ct5pERj/DN2d/wwCEP8P2S79n1kV058cUTmV08O+gsJixcHKZZdjM6t+kcdFZq1LlNZ3Kzcn0p6Qjlh+xHQpqyoMM0OSvXr+SIZ48gJyuHl497mdbNWgedJZNk80rncc+Uezh+x+PZtfuu5Gbncs6u5/DLBb9wzfBrePmHl9nu/u24bMJlrFizIujs1ilcEqYgr4Asaby37CzJoiC/wJegozG/ZjK1a7xnsDEpoKr836v/xw9Lf2D80ePt5pWhrvvgOiq0glv3ubXa9Lzmedyyzy38fP7PnLjTidw95W62+ec2/P2zv7O+Yn1Aua1bUUlRWpyrofwQc0rnpDSNcHHj7iTN1M6CDtOk3Pnpnbzw/Qvcvu/t7LfVfkFnx6TA14u+5vGZj3P+4PPp3b533GV65PXgscMfY8afZ/CHrn/g4ncuZocHduC5755rlJVNG3tvpBGp7pV09YbVLFm9JC2OhYnPgg7TZEz8dSJXvXcVx/Y71lqqZLDLJl5GuxbtuGb4NXUu279LfyacPIG3T3qb1rmtOe6F49ht7G5MKprkQ04Ts75iPQvKFqTFgzaUF2Je6byUNVFuzIPemcRY0GGahNnFsznhxRPo26kvY0eOtUpoGWrCrxOY8OsErt3jWtq3bJ/wegducyAz/jyDsSPHMqd0DsMfG85Rzx7FT8t+SmFuEzOnZA6KpsWDNpQfokIrWFC2ICXbr2o6nAYBmInPgg6T8dZsWMNRzx5FeWU5Lx37UqCDuJnUqais4LKJl9G7XW/O3fXceq+fnZXN6QNP56fzfuLmvW9m4m8T6fevfjz8xcMpyG3iIs1lG/O4KxGpbjZb1XQ4DQIwE58FHSajqSpnvXEWMxbO4KmjnmLbLbYNOksmRZ786km+XvQ1t+17G81zmm/2dlo3a821e1zLL+f/wvDQcMZMGMOilYuSmNP6Sadf9ykPOorDZEu2jTOUxizoMBntgc8f4MmvnuSGPW/gsD6HBZ0dkyKrN6zm2g+uZXD3wRzb79ikbLNzm848eNiDrC1fy3UfXJeUbW6OopIiBKEgvyCwPCQqEnT8vDw1o82GS8L0yOtBTpYNG5auLOgwDVJeWU5RSVHK2+Zvjk/Cn3DxOxczos8IrtszuIeGSb17p9zL/LL53LX/XUmtr9Nniz6ct+t5jJ0xlq8XfZ207dZHuCRM17ZdaZbdLJD066N1s9b069SPKXOnpGT71kdH+rNw0dSqdF0p4eJwVWBRVFJEUWlR1bR5ZfOo1EoACgsKGT1wNMf0OybwehPzSudxzPPH0Ltdb/575H8bdadKpmEWrVzE7ZNv54jtj2B4z+FJ3/51e17HE189wZgJY5jwxwm+V0JOl+ayEcNCwxj/7XgqtTLp1124OMxevfZK6jaNvyzoMAB8OudTPgl/QrikeoBRsq6k2nI5WTkU5BXQs11P9u69N6G8EKH8EMvXLOexmY9x+munc8HbF3Bcv+MYPXA0Q3sM9f0mva58HUc/fzQr16/kvVPeI79Fvq/pG3/d+NGNrNmwhtv3vT0l2+/QsgPX73k9F71zEW/98haHbHtIStKpSbg4zKBug3xNsyEKCwp56IuH+G7xd+zUeaekbXdDxQbmlc1LqwDMbMqCDsO/Pv8X5715HorSoWUHQvkherfvzZ4996Rnu56E8kNV/zq37lzjOCWXF17OlLlTGPvlWMZ/O56xM8ayQ8cdOH3g6Zy888m+jRtx4dsX8tncz3j+mOfpt2U/X9I0wfhh6Q88/MXDnDXoLLbruF3K0jl717N54PMHGDNhDPtvtT+52bkpSytapVYyp3QOo3YY5Ut6yVAYKgRgUtGkpAYdkVJVe72S3izoaMJUles/vJ6bP76ZEX1G8OSRT9KuRbvN3p6IsHvB7uxesDv/OPgfPPfdczw641Eum3gZV713FYdueyijB47m4G0PTllFsLFfjuWhLx7iisIrOLrv0SlJwzQeV7x7Ba1yW3H9ntenNJ1m2c2464C7OHz84Tz8xcOcO7j+TXI3x8KVC1lfsT6tHrS92/WmS5suTJ4zmbN3PTtp202nVjymZvaiu4kqryznz6//mZs/vpnTB5zOS8e91KCAI1abZm04feDpTDp9ErPOncUlQy/hs7mfMXL8SAruLeDKd69MesdL0+ZN45w3z2H/rfbnr/v8NanbNo3Px+GPee3H17hy2JV0at0p5emN6DOCvXvtzfUfXk/x2uKUpwdRPXCm0YNWRBgWGsbkOZOTul3royMzWNDRBK3ZsIZjnj+GR758hKuHXc1/Rv4npU3Qtu+4PX/b/2/MuXgOrx7/KoO7D+auT+9iu/u3Y/hjw3lsxmP8tuK3Bo15sXjVYkY9N4pubbsxbtQ4G6o+w1VqJZdOuJQeeT24aOhFvqQpItx9wN0sX7Ocv37sT1Bb9es+zR60hQWFzC6ezbzSeUnbZiQAS4dO0kzN7PVKE1O8tpiR40YyqWgS9x10H+cPOd+3tHOzcxm53UhGbjeShSsX8uRXT/LojEc5/bXTATcC6M6dd6Z/5/7uX5f+7LjljrTKbVXrdjdUbODY549l6eqlfHr6p2zRags/dscE6Nlvn+Xz+Z/z+OGP13l+JNPArgM5bcBp3DftPs4adBZbd9g6pemlU2+k0QoLXL2OyXMmJ63flHBxmM6tO9Mip0VStmeCYUFHEzK/bD4HPnUgPy79kXGjxnHcjscFlpcubbpweeHlXLb7ZcxYOIMv5n/BV4u+YubCmTz51ZOUrS8DIEuy2LbDtvTv0r9aMNK9bfeqVjGXT7ycj8If8d8j/8vArgMD2yfjj3Xl67j6/avp37k/f9z5j76nf8s+t/Dcd89x5XtX8vwxz6c0rXBxmHYt2pHXPC+l6STbgC4DaJXbislFSQw6rI+OjGBBRxPx49IfOfCpA1m2ZhlvnvRmoxnWXUTYpesu7NJ1l6pplVrJ7OLZfLXwK75a5P59Pu9znvvuuaplOrTsQP/O/eme152nvn6KCwZfEMgDyPjv/mn3M7t4NhP+OCGQ12jd2nbjisIr+MuHf+GT8Ccp6RskIt366IjIzc5lSPchSa3XES4J079z/6RtzwTDgo4mYNq8aRzy9CFkZ2Xz0WkfVXvAN0ZZksVW7bdiq/ZbceQOR1ZNL1lbwjeLv2HmwplVAcmL37/I3r325q4D7gowx8Yvy9cs55ZPbuGgbQ5i/633DywfY3Yfw0NfPMQlEy5h6p+mpqzzuaKSInq3752SbadaYUEht026jZXrVza4s0BVpaikiJF9RiYpdyYoFnT4REQeBQ4DFqvqjlHTzwfOBSqAN1T18mSm+/YvbzPquVF0adOFd/74Dtt02CaZm/dVfot8hoWGMSw0rGpapVYiiA1V30Tc8vEtlK4r5Y797gg0H61yW3Hbvrdxyiun8Mw3z6SslC1ckr49cBaGCqnQCqbOncq+W+3boG0tXrWYteVr7fVKBrDWK/55HDgoeoKI7A0cDvRX1X5AUn+u//er/zJi3Aj6bNGHyadPTuuAoyZZkmUBRxPx24rfuH/a/ZzW/7Skdjq1uU7a+SQGdRvEVe9dxeoNq5O+/eK1xZSuK03L1ysAu/XYDUGS8oqlqrlsmh4Ls5EFHT5R1Y+B5TGTzwZuV9V13jKLk5Xe3Z/ezSmvnMLw0HA+Ou0jurTpkqxNGxOIq9+7mtzsXG7a+6agswK4gPeeA+5hbulc7plyT9K3H2kum24tVyLyW+SzU+edkhN0pPmxMBtZ0BGsPsBwEZkqIh+JyK4N3WClVnLZhMu4dOKlHN33aN466a20q/luTKypc6fy7HfPMma3MXTP6x50dqoM7zmcUTuM4vZJt7OgbEFSt50JnWEVFhQyZc4UKiorGrSdTDgWxrGgI1g5QAdgKHAZ8JzU8K5ARM4UkekiMn3JkiVxN7ahYgOnvnIqd025i3N3PZfxo8bTPKd5yjJvTEMlcl6rKpdOvJQtW2/JZbtf5nMO6/a3/f7G+or1XPv+tUndbiZ0+11YUEjZ+jK+WfxNg7YTLg6T1zwvqb0mm2BY0BGsucBL6kwDKoGO8RZU1YdVdZCqDurUadMun1etX8XI8SN56uunuHnvm/nnwf+0XjlNo1fXeQ3w6o+vMqloEjftdRNtm7f1OYd127rD1lww5AIem/kYMxfOTNp2i0qKaJHTgi1bb5m0bfotMvjb5KKGvWJJ16bDZlMWdATrFWBvABHpAzQDlm7Ohj4p+oR3f3uXhw97mGv3uNYqV5qM8cw3z7BDxx0YvcvooLNSo2v3uJYOLTswZsKYBnXnHy1cEiaUH0rra7lnfk+6t+3e4Hod1jFY5rCgwyciMg6YAmwnInNFZDTwKLCViHwLjAdO1c28Yx20zUH8fP7PnPGHM5KXaWMagfFHj2fiyRNTOj5QQ7Vr0Y4b97qR939/n9d/ej0p28yEX/ciQmGosOFBR3H6HwvjWNDhE1U9QVW7qmquqvZQ1bGqul5V/6iqO6rqLqr6fkPS6NWuV5Jya0zjkSVZjaryaE3O/MOZbN9xey6deCkbKjY0eHvh4nBGtNYoLCikqKSIOSVzNmv9krUllKwrsaAjQ1jQYYwxSZCbnctd+9/FT8t+4t/T/92gba0tX8uiVYsy4kEbPfjb5rCWK5nFgg5jjEmSQ7Y9hP232p8bPryB5Wtiu+Wp2YaKDXw+73PunXIvo54bRc+/uwdsqkex9UP/Lv1pndt6syuTZkIrHrNR431JaowxaUZEuPuAuxnw0ABu+fgW7jkwfqdhK9evZMqcKUwqmsSkOZP4bO5nVb2a9m7XmwO3PpA9eu7BqB1G+Zn9lMjJymFoj6FMmjNps9a3ko7MYkGHMcYk0U6dd2L0wNHcP+1+zh50NttusS0LVy50AYb3b+bCmVRoBVmSRf/O/Rk9cDTDQsMoLChMi/or9VVYUMgtn9xC2bqyejd7DheHaZ7dPK2bDpuNLOgwxpgku2nvmxj37ThGjBtBeWU5v674FYCWOS0Z0mMIVw27iuE9hzO0x9Am0WNwYaiQSq3ks7mf1Xt04EjT4VSN5Gv8ZUGHMcYkWZc2Xbh1n1u5ffLtDO4+mLMHnc2w0DAGdh1Is+xmQWfPd0N7DCVLspg8Z/JmBR32aiVzWNBhjDEpcP6Q8zl/yPlBZ6NRyGuex86dd2ZSUf3rdYSLwxzW57AU5MoEwcqrjDHGpFxhQSGfzf2M8sryhNfJpKbDxrGgwxhjTMoVFhSyasMqvl70dcLrFJUUAdZyJZNY0GGMMSblhoWGAfUb/M366Mg8FnQYY4xJuYL8AgryCurVX4f10ZF5LOgwxhjji8JQIZOLJic8Em+4OOzG3mmbeX2XNFUWdBhjjPFFYUEh88rmVdXVqEtRaRHd23YnNzs3xTkzfrGgwxhjjC+q6nUkOPhbuNj66Mg0FnQYY4zxxU5b7kTbZm0T7q8jXBK2SqQZxoIOY4wxvsjOymZoj6EJlXRUVFYwt3SuBR0ZxoIOY4wxviksKOSbRd9Qsrak1uXml82nvLLcXq9kGAs6jDHG+GZYaBiK8tncz2pdLtJcNpQf8iNbxicWdBhjjPHNkB5DyJbsOut1WMdgmcmCDmOMMb5p06wN/bv0r7Neh5V0ZCYLOowxxviqsKCQqfOmsqFiQ43LhIvDdGzVkdbNWvuYM5NqFnQYY4zx1bDQMFZvWM3MhTNrXMaay2YmCzqMMcb4qrCgEKi9k7BwiXUMloks6DDGGOOr7nnd6Znfs8agQ1Vdb6RW0pFxLOgwxhjju9oGf1u6eilrytdY0JGBLOgwxhjju8KCQhasXMDvxb9vMs+GtM9cFnQYY4zxXdXgb0WbvmKxPjoylwUdPhGRR0VksYh8G2feGBFREekYRN6MMcZv/Tr1I695Xtx6HVbSkbks6PDP48BBsRNFpAA4ACjyO0PGGBOU7KxsduuxW/ygozhMm2ZtaN+ifQA5M6lkQYdPVPVjYHmcWfcClwOb1qYyxpgMVlhQyLeLv2XFmhXVpkf66BCRgHJmUsWCjgCJyOHAPFX9KoFlzxSR6SIyfcmSJT7kzpjUs/O6aYvU65gyd0q16dZHR+ayoCMgItIKuBr4SyLLq+rDqjpIVQd16tQptZkzxid2Xjdtg7sPJluyN6lMan10ZC4LOoKzNdAb+EpEZgM9gC9FpEuguTLGGJ+0btaagV0HVqvXUbaujBVrV1jQkaEs6AiIqn6jqluqai9V7QXMBXZR1YUBZ80YY3wTGfxtfcV6wFquZDoLOnwiIuOAKcB2IjJXREYHnSdjjAnasNAw1pavZcaCGYD10ZHpcoLOQFOhqifUMb+XT1kxxphGI3rwtyE9hlhJR4azkg5jjDGB6dq2K73b9a6q1xEuDtMsuxld2lj1tkxkQYcxxphAFYYKmVQ0CVWlqLSIgrwCssQeT5nIvlVjjDGBGlYwjMWrFvPril9dc1l7tZKxLOgwxhgTqMKQV6+jaHJVb6QmM1nQYYwxJlB9O/WlXYt2vD/7fRaULbCgI4NZ0GGMMSZQWZLFbj1245UfXkFRQvmhoLNkUsSCDmOMMYEbFhpG6bpSwJrLZjILOowxxgQu0l8HWMdgmcyCDmOMMYHbtfuu5GTlIAgF+QVBZ8ekiAUdxhhjAtcqtxW7dN2Frm270iy7WdDZMSli3aAbY4xpFG7c60YWrrQxLzOZBR3GGGMahYO2OSjoLJgUs9crxhhjjPGFBR3GGGOM8YUFHcYYY4zxhQUdxhhjjPGFBR3GGGOM8YUFHcYYY4zxhQUdxhhjjPGFBR3GGGOM8YWoatB5MPUkIkuAcJxZHYGlPmfH0g4m7VSm21NVO6Vo2zWq5byGpvkdB5l2Ju5zIOe1qc6CjgwiItNVdZClnflpB7nPQWiK33GQaTfFfTb+sNcrxhhjjPGFBR3GGGOM8YUFHZnlYUu7yaQd5D4HoSl+x0Gm3RT32fjA6nQYY4wxxhdW0mGMMcYYX1jQkSFE5CAR+VFEfhGRK31Mt0BEPhCR70XkOxG50K+0vfSzRWSGiLzuc7rtROQFEflBRGaJyG4+pn2xd6y/FZFxItLCr7SDEMS5HfR57eXBzu0MP7ebIgs6MoCIZAMPAAcDfYETRKSvT8mXA2NUtS8wFDjXx7QBLgRm+ZhexD+At1V1e6C/X3kQke7ABcAgVd0RyAaO9yPtIAR4bgd9XoOd2xl9bjdVFnRkhsHAL6r6m6quB8YDh/uRsKouUNUvvb/LcDeo7n6kLSI9gEOB//iRXlS6+cAewFgAVV2vqsU+ZiEHaCkiOUArYL6PafstkHM7yPMa7NxuIud2k2RBR2boDsyJ+jwXH2+QESLSCxgITPUpyb8DlwOVPqUX0RtYAjzmFX//R0Ra+5Gwqs4D7gKKgAVAiapO8CPtgAR+bgdwXoOd203h3G6SLOgwSSEibYAXgYtUtdSH9A4DFqvqF6lOK44cYBfg36o6EFgF+FXXoD3ul35voBvQWkT+6EfaTZHf57WXpp3bdm5nLAs6MsM8oCDqcw9vmi9EJBd3Y35aVV/yKdlCYKSIzMYVue8jIk/5lPZcYK6qRn75voC7UfthP+B3VV2iqhuAl4DdfUo7CIGd2wGd12DndlM5t5skCzoyw+fAtiLSW0Sa4SpfveZHwiIiuPe/s1T1Hj/SBFDVq1S1h6r2wu3v+6rqy68iVV0IzBGR7bxJ+wLf+5E2ruh5qIi08o79vgRT2dAvgZzbQZ3XYOd2Ezq3m6ScoDNgGk5Vy0XkPOAdXI3vR1X1O5+SLwROBr4RkZnetKtV9U2f0g/K+cDT3oPwN+D//EhUVaeKyAvAl7gWFjPI4B4cAzy3m+p5DXZumxSyHkmNMcYY4wt7vWKMMcYYX1jQYYwxxhhfWNBhjDHGGF9Y0GGMMcYYX1jQYYwxxhhfWNBhjDHGGF9Y0GGMMcYYX1jQYYwxxhhfWNBhjDHGGF9Y0GGMMcYYX1jQYYwxxhhfWNBhTBMjIiu9/3uJyIlJ3vbVMZ8/Teb2jTHpzYIOY5quXkC9gg4RqWtk6mpBh6ruXs88GWMymAUdxjRdtwPDRWSmiFwsItkicqeIfC4iX4vInwFEZC8R+UREXgO+96a9IiJfiMh3InKmN+12oKW3vae9aZFSFfG2/a2IfCMix0Vt+0MReUFEfhCRp0VEItsTke+9vNzl+9ExxiRdXb9ajDGZ60rgUlU9DMALHkpUdVcRaQ5MFpEJ3rK7ADuq6u/e59NVdbmItAQ+F5EXVfVKETlPVQfESesoYADQH+jorfOxN28g0A+YD0wGCkVkFnAksL2qqoi0S+6uG2OCYCUdxpiIA4BTRGQmMBXYAtjWmzctKuAAuEBEvgI+AwqilqvJMGCcqlao6iLgI2DXqG3PVdVKYCbutU8JsBYYKyJHAasbuG/GmEbAgg5jTIQA56vqAO9fb1WNlHSsqlpIZC9gP2A3Ve0PzABaNCDddVF/VwA5qloODAZeAA4D3m7A9o0xjYQFHcY0XWVA26jP7wBni0gugIj0EZHWcdbLB1ao6moR2R4YGjVvQ2T9GJ8Ax3n1RjoBewDTasqYiLQB8lX1TeBi3GsZY0yaszodxjRdXwMV3muSx4F/4F5tfOlV5lwCHBFnvbeBs7x6Fz/iXrFEPAx8LSJfqupJUdNfBnYDvgIUuFxVF3pBSzxtgVdFpAWuBOaSzdpDY0yjIqoadB6MMcYY0wTY6xVjjDHG+MKCDmOMMcb4woIOY4wxxvjCgg5jjDHG+MKCDmOMMcb4woIOY4wxxvjCgg5jjDHG+MKCDmOMMcb44v8BmXQ17oBFoxwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#if (not policy_selected =='full_grid'):\n",
    "print(\"Selected policy {}, time horizon {}, initial price {} and number of iterations {}\".format(policy_selected,T,initPrice,nIterations))\n",
    "contribution_iterations=[P.run_policy(param_list, policy_info, policy_selected, t) for ite in list(range(nIterations))]\n",
    "\n",
    "contribution_iterations = pd.Series(contribution_iterations)\n",
    "print(\"Contribution per iteration: \")\n",
    "print(contribution_iterations)\n",
    "cum_avg_contrib = contribution_iterations.expanding().mean()\n",
    "print(\"Cumulative average contribution per iteration: \")\n",
    "print(cum_avg_contrib)\n",
    "        \n",
    "#plotting the results\n",
    "\n",
    "fig, axsubs = plt.subplots(1,2,sharex=True,sharey=True)\n",
    "fig.suptitle(\"Asset selling using policy {} with parameters {} and T {}\".format(policy_selected,policy_info[policy_selected],T) )\n",
    "i = np.arange(0, nIterations, 1)\n",
    "        \n",
    "axsubs[0].plot(i, cum_avg_contrib, 'g')\n",
    "axsubs[0].set_title('Cumulative average contribution')\n",
    "          \n",
    "axsubs[1].plot(i, contribution_iterations, 'g')\n",
    "axsubs[1].set_title('Contribution per iteration')\n",
    "        \n",
    "    \n",
    "# Create a big subplot\n",
    "ax = fig.add_subplot(111, frameon=False)\n",
    "# hide tick and tick label of the big axes\n",
    "plt.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
    "\n",
    "ax.set_ylabel('USD', labelpad=0) # Use argument `labelpad` to move label downwards.\n",
    "ax.set_xlabel('Iterations', labelpad=10)\n",
    "        \n",
    "plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_selected =='full_grid'\n",
    "# obtain the theta values to carry out a full grid search\n",
    "grid_search_theta_values = P.grid_search_theta_values(sheet2['low_min'], sheet2['low_max'], sheet2['high_min'], sheet2['high_max'], sheet2['increment_size'])\n",
    "# use those theta values to calculate corresponding contribution values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grid_search_theta_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.059625827446253  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5477912175212573  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.3124863733250671  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.10313373740931653  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.9406508051209478  curr_bias  Up  new_bias  Neutral\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.1684888435118309  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5596119153998756  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.0822272722864622  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5274427850588601  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.659612184607769  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.8192467709434913  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.7904571341772412  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.48277880352613  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.6008635295301037  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.01567889516764942  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.015198329473851135  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.04416605401500773  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.3819335365697125  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.7016407254976783  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.4200826679344263  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5958557808984619  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.6582979525387146  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.19715303016648633  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.2614885787921005  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.35641422250624544  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.08552695016328382  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.3661581557710999  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.09180613281881622  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.3302079574424508  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.05542327085207277  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.6495978578496083  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.4950676887318336  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.20487328024557938  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.8941509386415077  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.08348619481447239  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.7729678258663791  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.6976020329558196  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5135025049203482  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5469790907067655  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.3183849411530906  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.17631349173733113  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5186201296745278  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.3146362725997548  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.7619000213669831  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.1548372299232612  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.7417806973519159  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.8138742254236002  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.9958617901494262  curr_bias  Up  new_bias  Neutral\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.2814278972459371  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.4478735178748525  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.7635280109100959  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.6345585884352359  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.3908406643529526  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5110902280758459  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.23869951689225555  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.8752818516301238  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.25143609145860135  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.27106862367576967  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.8241729519750237  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5646394830128394  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.42612102625298676  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.8128832648501544  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.27005933402811255  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.053376652731436325  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.3945020025393071  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.7954696765266511  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.947339595548537  curr_bias  Up  new_bias  Neutral\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.4952181013536874  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.08796455529133362  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5675620265959185  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.979107232460737  curr_bias  Up  new_bias  Neutral\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.13653558674628563  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.22227093730859782  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.8486244960339273  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.3366588534691112  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.21445935317505804  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.7085391054840665  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5772954992226518  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5196562979191857  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5329130843734448  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.9033219325411262  curr_bias  Up  new_bias  Neutral\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5199178359547055  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.9989253406169298  curr_bias  Up  new_bias  Neutral\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.22638112315006254  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.8966040135637273  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.21449368219534193  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5521642806220787  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.2743164008088571  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5083942253298411  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.7241429280830625  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.1626505904274188  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5813966200532049  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.4240624187776365  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.33405458876378247  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.09581713271514325  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.4755787772628176  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.35059297453378224  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.9279112219015438  curr_bias  Up  new_bias  Neutral\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.20389268299420404  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.21598751712182673  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.07419024803917873  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.03611685083756144  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.7684121985970839  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.7101719107857338  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.4682139918349948  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.0037233007039758625  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5462432413028787  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.3609343010190801  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.7231125423054038  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.8173417259140272  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5216509002457363  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.9575119829302672  curr_bias  Up  new_bias  Neutral\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.9786092003422285  curr_bias  Up  new_bias  Neutral\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.7824855623124374  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.46224179147783695  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.7025251970961777  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.49241202677360063  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.09639646347111164  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5465760573070179  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.6267953254056897  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.04364867746440937  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.25740518296177717  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.8189962901897864  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.7239557150039996  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.29026468356704993  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.10386887022925406  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.7155420100221593  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.453123608476127  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.581593544514928  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.6215054866902109  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.7309456577059659  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.23804527034193113  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.15739913139805328  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5124802779289894  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.37479086340282275  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.7723473468243091  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.6743035964354331  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5294573304234017  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.15878254984344176  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.23258558547423547  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.1005856395391379  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.3913559259085313  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.09103436954722466  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.8633502147749378  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.9770510819328783  curr_bias  Up  new_bias  Neutral\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.6658260364720088  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.6657026611155845  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.7361290856803555  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.758491129270247  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.23710545630961577  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.40336844057193133  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.1210093797617311  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.0689679819779836  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.15693822776101352  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.1722982803413381  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.19806801498454651  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.36739724772001714  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.186963738020115  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.8413187128250093  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.4931112813996169  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.31998384746605457  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.18853468436664356  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.8139437275757037  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.3495036616293572  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.9993962768076438  curr_bias  Up  new_bias  Neutral\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.1354733241433962  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.9213578988384137  curr_bias  Up  new_bias  Neutral\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.09912658454038403  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.2365136439079537  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.2877969530013714  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.6273410471314673  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5908814703138637  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.4061302380279619  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.9102280509487  curr_bias  Up  new_bias  Neutral\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.6275392425921726  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.4981583070625498  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.7921475423156947  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.17098812275393904  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.44899374490217947  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.7262075083318685  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.8350865251575104  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.36991028910931856  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.49596284861832496  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.24520149674899827  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.3371286195817167  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.21362771108192524  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.3908065250646414  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.1968112305941645  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.21448630418613235  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.9733588536154112  curr_bias  Up  new_bias  Neutral\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.44575938107662616  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.51386141908312  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.062300606258574254  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.8046052802625742  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.936357889420308  curr_bias  Up  new_bias  Neutral\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.845526445271649  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.12352783284131541  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.44293637576559763  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5094000421763388  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.47459288922756404  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.18590725954813914  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.30392164170043023  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.3480229444897788  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.8872588578191919  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.15417428864275384  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.3320445479229681  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.3979770633130483  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.621830380874947  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.2571450992238564  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.10765674050307494  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.21159810093802067  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.1779258961519069  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.322458657612253  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.09214214105699858  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.6618029462943942  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.21694597430140572  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.30929096405150003  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.7118383107395528  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.9705949758462649  curr_bias  Up  new_bias  Neutral\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.8954717762105713  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.724180045359918  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.6405077851241651  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5381528904269811  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.3103346820920315  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5117450676415145  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.3064108209707258  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.6694145424676555  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.35517977103926734  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.9391590590558626  curr_bias  Up  new_bias  Neutral\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.538406884730934  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5713360605171846  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.6046123203925141  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.18547411275469827  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.8791305791967198  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.7535924882911905  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.17246521697407635  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.9271839972039936  curr_bias  Up  new_bias  Neutral\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.15478123011988687  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.974945570660559  curr_bias  Up  new_bias  Neutral\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5698984593718842  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.07527831520902994  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.8145363043106949  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5207088734398683  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5974001871711134  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.550856996611958  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([0.01])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.35210228055326387  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([1.2575])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.5844314606507931  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([2.505])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.9067331874003017  curr_bias  Up  new_bias  Neutral\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([3.7525])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.32976699057363623  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "policy_dict={'sell_low': (2, nan), 'high_low': (array([0.]), array([5.])), 'track': (0, 4.0, 20.26712226359752)}\n",
      "time=0, obj=0.0, s.resource=1, s.price=16, x=Decision(sell=1, hold=0)\n",
      "coin  0.775478950461835  curr_bias  Up  new_bias  Up\n",
      "obj=16.0, state.resource=0\n",
      "cum_avg_contrib\n",
      "[[16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16.\n",
      "  16. 16. 16. 16. 16. 16. 16.]\n",
      " [16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16.\n",
      "  16. 16. 16. 16. 16. 16. 16.]\n",
      " [16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16.\n",
      "  16. 16. 16. 16. 16. 16. 16.]\n",
      " [16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16.\n",
      "  16. 16. 16. 16. 16. 16. 16.]\n",
      " [16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16.\n",
      "  16. 16. 16. 16. 16. 16. 16.]\n",
      " [16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16.\n",
      "  16. 16. 16. 16. 16. 16. 16.]\n",
      " [16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16.\n",
      "  16. 16. 16. 16. 16. 16. 16.]\n",
      " [16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16.\n",
      "  16. 16. 16. 16. 16. 16. 16.]\n",
      " [16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16.\n",
      "  16. 16. 16. 16. 16. 16. 16.]\n",
      " [16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16.\n",
      "  16. 16. 16. 16. 16. 16. 16.]]\n",
      "Ite 0, n 0 and plot (0,0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peyman/miniconda3/envs/jupyterlab-debugger/lib/python3.9/site-packages/matplotlib/text.py:1165: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if s != self._text:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '[0.01]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-97d223637b78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# plot those contribution values on a heat map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_heat_map_many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcum_avg_contrib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_search_theta_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_search_theta_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprintIterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/PhD_UiS/seqdec_powell_repo/Chap2_Assett_Selling/function/AssetSellingPolicy.py\u001b[0m in \u001b[0;36mplot_heat_map_many\u001b[0;34m(self, contribution_values, theta_low_values, theta_high_values, iterations)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;31m# get the current labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mlabelsx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m             \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabelsx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;31m# get the current labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/PhD_UiS/seqdec_powell_repo/Chap2_Assett_Selling/function/AssetSellingPolicy.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;31m# get the current labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mlabelsx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m             \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabelsx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;31m# get the current labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '[0.01]'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "policy_selected =='full_grid'\n",
    "# obtain the theta values to carry out a full grid search\n",
    "grid_search_theta_values = P.grid_search_theta_values(sheet2['low_min'], sheet2['low_max'], sheet2['high_min'], sheet2['high_max'], sheet2['increment_size'])\n",
    "# use those theta values to calculate corresponding contribution values\n",
    "        \n",
    "contribution_iterations = [P.vary_theta(param_list, policy_info, \"high_low\", t, grid_search_theta_values[0]) for ite in list(range(nIterations))]\n",
    "\n",
    "contribution_iterations_arr = np.array(contribution_iterations)\n",
    "cum_sum_contrib = contribution_iterations_arr.cumsum(axis=0)\n",
    "nElem = np.arange(1,cum_sum_contrib.shape[0]+1).reshape((cum_sum_contrib.shape[0],1))\n",
    "cum_avg_contrib=cum_sum_contrib/nElem\n",
    "print(\"cum_avg_contrib\")\n",
    "print(cum_avg_contrib)\n",
    "    \n",
    "        # plot those contribution values on a heat map\n",
    "P.plot_heat_map_many(cum_avg_contrib, grid_search_theta_values[1], grid_search_theta_values[2], printIterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(np.linspace)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('jupyterlab-debugger': conda)",
   "language": "python",
   "name": "python39164bitjupyterlabdebuggerconda9f0223ea840b42a4bb0b5831fc210e72"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
